import os, requests, gzip, shutil
import xml.etree.ElementTree as ET
import pandas as pd
from tqdm import tqdm
from datetime import datetime
from bs4 import BeautifulSoup

# ğŸ”§ è¨­å®šæ—¥æœŸï¼ˆYYYYMMDDï¼‰
target_date = "20250616"
base_url = f"https://tisvcloud.freeway.gov.tw/history/motc20/VD/{target_date}/"
folder = f"vd_{target_date}"
os.makedirs(folder, exist_ok=True)

# ğŸš— è»Šå‹åŠ æ¬Šè¨­å®š
VEHICLE_WEIGHT = {"S": 1.0, "L": 1.5, "T": 1.5}

# ğŸ” æŠ“å‡ºç¶²é ä¸Šå¯ä¸‹è¼‰çš„ .gz æª”æ¡ˆ
try:
    r = requests.get(base_url, timeout=20)
    r.raise_for_status()
except Exception as e:
    print(f"âŒ ç„¡æ³•é€£ç·šç¶²ç«™ï¼š{e}")
    exit()

soup = BeautifulSoup(r.text, "html.parser")
gz_files = [a["href"] for a in soup.find_all("a") if a["href"].endswith(".xml.gz")]
print(f"ğŸ“‚ æ‰¾åˆ° {len(gz_files)} ç­†æª”æ¡ˆ")

# â¬‡ ä¸‹è¼‰æ‰€æœ‰ .gz
for name in tqdm(gz_files, desc="ä¸‹è¼‰æª”æ¡ˆ"):
    url = base_url + name
    path = os.path.join(folder, name)
    if not os.path.exists(path):
        try:
            r = requests.get(url, timeout=10)
            if r.status_code == 200:
                with open(path, "wb") as f:
                    f.write(r.content)
        except:
            continue

# ğŸ“‚ è§£å£“æ‰€æœ‰ .gz â†’ .xml
for file in os.listdir(folder):
    if file.endswith(".gz"):
        gz_path = os.path.join(folder, file)
        xml_path = gz_path[:-3]
        if not os.path.exists(xml_path):
            try:
                with gzip.open(gz_path, "rb") as f_in, open(xml_path, "wb") as f_out:
                    shutil.copyfileobj(f_in, f_out)
            except:
                pass

# ğŸ” å‘½åç©ºé–“
#ns = {"vd": "http://traffic.device/VDLive.xsd"}
#records = []
