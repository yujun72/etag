import os, requests, gzip, shutil
from tqdm import tqdm
from bs4 import BeautifulSoup

# âœ… æ¬²æŠ“å–çš„ä¸€é€±æ—¥æœŸï¼ˆè‡ªè¡ŒæŒ‡å®šï¼‰
dates = ["20250621"]

# âœ… æ¯ 5 åˆ†é˜ä¸€ç­†çš„æ™‚é–“é»ï¼ˆå…± 288 ç­†ï¼‰
valid_times = [f"{h:02d}{m:02d}" for h in range(24) for m in range(0, 60, 5)]

for date in dates:
    base_url = f"https://tisvcloud.freeway.gov.tw/history/motc20/VD/{date}/"
    folder = f"vd_{date}"
    os.makedirs(folder, exist_ok=True)

    print(f"\nğŸ“… è™•ç†æ—¥æœŸï¼š{date}")

    # ğŸ” æŠ“å‡ºç•¶å¤©æ‰€æœ‰ .gz æª”æ¡ˆé€£çµ
    try:
        r = requests.get(base_url, timeout=20)
        r.raise_for_status()
    except Exception as e:
        print(f"âŒ ç„¡æ³•é€£ç·šï¼š{base_url}ï¼ŒéŒ¯èª¤ï¼š{e}")
        continue

    soup = BeautifulSoup(r.text, "html.parser")
    all_files = [a["href"] for a in soup.find_all("a") if a["href"].endswith(".xml.gz")]
    gz_files = [f for f in all_files if f[7:11] in valid_times]

    print(f"ğŸ” æ‰¾åˆ° {len(gz_files)} ç­†æ¯ 5 åˆ†é˜æª”æ¡ˆ")

    # â¬‡ ä¸‹è¼‰ .gz
    for name in tqdm(gz_files, desc=f"â¬‡ ä¸‹è¼‰ {date}"):
        url = base_url + name
        path = os.path.join(folder, name)
        if not os.path.exists(path):
            try:
                r = requests.get(url, timeout=10)
                if r.status_code == 200:
                    with open(path, "wb") as f:
                        f.write(r.content)
            except Exception as e:
                print(f"âš ï¸ ä¸‹è¼‰å¤±æ•— {name}: {e}")

    # ğŸ—œ è§£å£“ .gz â†’ .xml
    for file in os.listdir(folder):
        if file.endswith(".gz"):
            gz_path = os.path.join(folder, file)
            xml_path = gz_path[:-3]
            if not os.path.exists(xml_path):
                try:
                    with gzip.open(gz_path, "rb") as f_in, open(xml_path, "wb") as f_out:
                        shutil.copyfileobj(f_in, f_out)
                except Exception as e:
                    print(f"âš ï¸ è§£å£“å¤±æ•— {file}: {e}")

print("\nâœ… æ‰€æœ‰æ—¥æœŸè³‡æ–™ä¸‹è¼‰èˆ‡è§£å£“å®Œæˆï¼")
